{"cells":[{"cell_type":"code","execution_count":1,"id":"4ff8f7a5","metadata":{},"outputs":[],"source":["from pyspark.sql import SparkSession"]},{"cell_type":"code","execution_count":2,"id":"b164f4c8","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Safe mode is OFF\r\n"]}],"source":["!hdfs dfsadmin -safemode leave"]},{"cell_type":"code","execution_count":3,"id":"9a91d7fd","metadata":{},"outputs":[],"source":["from pyspark.sql import SparkSession"]},{"cell_type":"code","execution_count":4,"id":"f0d7c7d2","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Setting default log level to \"WARN\".\n","To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n","24/10/26 20:32:09 INFO SparkEnv: Registering MapOutputTracker\n","24/10/26 20:32:09 INFO SparkEnv: Registering BlockManagerMaster\n","24/10/26 20:32:09 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n","24/10/26 20:32:09 INFO SparkEnv: Registering OutputCommitCoordinator\n"]}],"source":["# Create a Spark session with increased executor memory\n","spark = SparkSession.builder \\\n","    .appName(\"MyApp\") \\\n","    .config(\"spark.executor.memory\", \"8g\") \\\n","    .config(\"spark.driver.memory\", \"8g\") \\\n","    .getOrCreate()"]},{"cell_type":"code","execution_count":5,"id":"f683ff2f","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["                                                                                \r"]}],"source":["df = spark.read.csv(\"gs://my-bigdatatech-project-jl/landing/itineraries.csv\", header=True, inferSchema=True)"]},{"cell_type":"code","execution_count":6,"id":"f9e766f9","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 2:======================================================>(124 + 1) / 125]\r"]},{"name":"stdout","output_type":"stream","text":["Number of records: 44589769\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["print(f\"Number of records: {df.count()}\")\n"]},{"cell_type":"code","execution_count":7,"id":"ac4f4740","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['legId', 'searchDate', 'flightDate', 'startingAirport', 'destinationAirport', 'fareBasisCode', 'travelDuration', 'elapsedDays', 'isBasicEconomy', 'isRefundable', 'isNonStop', 'baseFare', 'totalFare', 'seatsRemaining', 'totalTravelDistance', 'segmentsDepartureTimeEpochSeconds', 'segmentsDepartureTimeRaw', 'segmentsArrivalTimeEpochSeconds', 'segmentsArrivalTimeRaw', 'segmentsArrivalAirportCode', 'segmentsDepartureAirportCode', 'segmentsAirlineName', 'segmentsAirlineCode', 'segmentsEquipmentDescription', 'segmentsDurationInSeconds', 'segmentsDistance', 'segmentsCabinCode']\n"]}],"source":["# List of variables\n","variables = df.columns\n","print(variables)"]},{"cell_type":"code","execution_count":8,"id":"5bf01a24","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["24/10/26 20:33:54 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n","[Stage 5:======================================================>(124 + 1) / 125]\r"]},{"name":"stdout","output_type":"stream","text":["+-----+----------+----------+---------------+------------------+-------------+--------------+-----------+--------------+------------+---------+--------+---------+--------------+-------------------+---------------------------------+------------------------+-------------------------------+----------------------+--------------------------+----------------------------+-------------------+-------------------+----------------------------+-------------------------+----------------+-----------------+\n","|legId|searchDate|flightDate|startingAirport|destinationAirport|fareBasisCode|travelDuration|elapsedDays|isBasicEconomy|isRefundable|isNonStop|baseFare|totalFare|seatsRemaining|totalTravelDistance|segmentsDepartureTimeEpochSeconds|segmentsDepartureTimeRaw|segmentsArrivalTimeEpochSeconds|segmentsArrivalTimeRaw|segmentsArrivalAirportCode|segmentsDepartureAirportCode|segmentsAirlineName|segmentsAirlineCode|segmentsEquipmentDescription|segmentsDurationInSeconds|segmentsDistance|segmentsCabinCode|\n","+-----+----------+----------+---------------+------------------+-------------+--------------+-----------+--------------+------------+---------+--------+---------+--------------+-------------------+---------------------------------+------------------------+-------------------------------+----------------------+--------------------------+----------------------------+-------------------+-------------------+----------------------------+-------------------------+----------------+-----------------+\n","|    0|         0|         0|              0|                 0|            1|             1|          1|             1|           1|        1|       1|        1|             1|            3718047|                                1|                       1|                              1|                     1|                         1|                           1|                  1|                  1|                      883152|                        1|               1|                1|\n","+-----+----------+----------+---------------+------------------+-------------+--------------+-----------+--------------+------------+---------+--------+---------+--------------+-------------------+---------------------------------+------------------------+-------------------------------+----------------------+--------------------------+----------------------------+-------------------+-------------------+----------------------------+-------------------------+----------------+-----------------+\n","\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["from pyspark.sql import functions as F\n","\n","# Number of missing values per column\n","missing_values = df.select([F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in df.columns])\n","\n","# Show result\n","missing_values.show()"]},{"cell_type":"code","execution_count":9,"id":"1aef165e","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 8:======================================================>(124 + 1) / 125]\r"]},{"name":"stdout","output_type":"stream","text":["Number of null values in segmentsEquipmentDescription: 883152\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["from pyspark.sql.functions import col, when\n","\n","def count_nulls(df, segmentsEquipmentDescription):\n","    \"\"\"\n","    Function to count the number of null values in a given column of a DataFrame.\n","    \n","    :param df: The PySpark DataFrame\n","    :param column_name: The column for which to count null values\n","    :return: The count of null values in the specified column\n","    \"\"\"\n","    return df.select(when(col(segmentsEquipmentDescription).isNull(), 1).alias(segmentsEquipmentDescription)).groupBy().sum(segmentsEquipmentDescription).collect()[0][0]\n","\n","# Example usage\n","null_count = count_nulls(df, \"segmentsEquipmentDescription\")\n","print(f\"Number of null values in segmentsEquipmentDescription: {null_count}\")\n"]},{"cell_type":"code","execution_count":10,"id":"394f847a","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 11:=====================================================>(124 + 1) / 125]\r"]},{"name":"stdout","output_type":"stream","text":["Number of null values in totalTravelDistance: 3718047\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["def count_nulls(df, totalTravelDistance):\n","    \"\"\"\n","    Function to count the number of null values in a given column of a DataFrame.\n","    \n","    :param df: The PySpark DataFrame\n","    :param column_name: The column for which to count null values\n","    :return: The count of null values in the specified column\n","    \"\"\"\n","    return df.select(when(col(totalTravelDistance).isNull(), 1).alias(totalTravelDistance)).groupBy().sum(totalTravelDistance).collect()[0][0]\n","\n","null_count = count_nulls(df, \"totalTravelDistance\")\n","print(f\"Number of null values in totalTravelDistance: {null_count}\")"]},{"cell_type":"code","execution_count":11,"id":"d61520ae","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+----------------------------+\n","|segmentsEquipmentDescription|\n","+----------------------------+\n","|                 Airbus A321|\n","|                 Airbus A321|\n","|              Boeing 757-200|\n","|                 Airbus A321|\n","|                 Airbus A321|\n","|                        NULL|\n","|        Airbus A320||Airb...|\n","|        Airbus A320||Boei...|\n","|        Airbus A319||Airb...|\n","|        Airbus A319||Boei...|\n","+----------------------------+\n","only showing top 10 rows\n","\n"]}],"source":["# Get the first 10 rows of the segmentsEquipmentDescription column\n","df.select(\"segmentsEquipmentDescription\").show(10)"]},{"cell_type":"code","execution_count":null,"id":"02942525","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 15:=============>                                         (30 + 6) / 125]\r"]}],"source":["# Get statistics with df.describe() function\n","# find min, max, avg, std dev for all numeric variables\n","numeric_stats = df.describe() \n","numeric_stats.show()"]},{"cell_type":"code","execution_count":null,"id":"b9096a38","metadata":{},"outputs":[],"source":["from pyspark.sql import functions as F\n","\n","# get min and max dates for date variables\n","columns = df.columns\n","\n","date_columns = [c for c in columns if 'date' in c.lower()]\n","\n","for date_col in date_columns:\n","    min_date = df.select(F.min(date_col)).first()[0]\n","    max_date = df.select(F.max(date_col)).first()[0]\n","    print(f\"{date_col} - Min date: {min_date}, Max date: {max_date}\")"]},{"cell_type":"code","execution_count":null,"id":"90ef5f5e","metadata":{},"outputs":[],"source":["# Filter the Spark DataFrame (example condition)\n","filtered_df = df.filter(df.totalFare.isNotNull() & df.segmentsEquipmentDescription.isNotNull())\n","\n","# Limit to 10 rows\n","limited_df = filtered_df.limit(50)\n","\n","# Convert to Pandas DataFrame\n","pandas_df = limited_df.toPandas()"]},{"cell_type":"code","execution_count":null,"id":"b90873c0","metadata":{},"outputs":[],"source":["import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Set the size of the plot\n","plt.figure(figsize=(12, 6))\n","\n","# Create a boxplot\n","sns.boxplot(x='segmentsEquipmentDescription', y='totalFare', data=pandas_df)\n","\n","# Set title and labels\n","plt.title('Boxplot of Total Fare vs. Equipment Description')\n","plt.xlabel('Segments Equipment Description')\n","plt.ylabel('Total Fare')\n","\n","plt.yticks(fontsize=10)  \n","plt.xticks(fontsize=10)\n","\n","# Rotate x-axis labels for better readability (if needed)\n","plt.xticks(rotation=90)\n","\n","# Show the plot\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"e64ee8fb","metadata":{},"outputs":[],"source":["# get distribution of total fare for one-way flights\n","plt.figure(figsize=(10, 6))\n","sns.histplot(pandas_df['totalFare'], bins=30, kde=True)\n","plt.title('distribution of fare for One-Way Flights')\n","plt.xlabel('total fare (USD)')\n","plt.ylabel('frequency')\n","plt.grid()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"1426a333","metadata":{},"outputs":[],"source":["# scatterplot to see if seats remaining and total fare have a strong correlation\n","plt.figure(figsize=(10, 6))\n","sns.scatterplot(x='seatsRemaining', y='totalFare', data=pandas_df)\n","plt.title('Seats Remaining vs. Total Fare')\n","plt.xlabel('Seats Remaining')\n","plt.ylabel('Total Fare (USD)')\n","plt.grid()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"f8536264","metadata":{},"outputs":[],"source":["# travel distance vs total fare\n","plt.figure(figsize=(12, 6))\n","sns.boxplot(x='totalTravelDistance', y='totalFare', data=pandas_df)\n","plt.title('Total Fare vs. Travel Distance')\n","plt.xlabel('Total Travel Distance (Miles)')\n","plt.ylabel('Total Fare (USD)')\n","plt.grid()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"0bff40d7","metadata":{},"outputs":[],"source":["# travel duration vs total fare\n","plt.figure(figsize=(10, 6))\n","sns.scatterplot(x='travelDuration', y='totalFare', data=pandas_df)\n","plt.title('Relationship Between Travel Duration and Total Fare')\n","plt.xlabel('Travel Duration (HH:MM)')\n","plt.ylabel('Total Fare (USD)')\n","plt.grid()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"2d9e51bb","metadata":{},"outputs":[],"source":["# ticket price over time\n","import pandas as pd\n","\n","pandas_df['searchDate'] = pd.to_datetime(pandas_df['searchDate'])\n","average_fare_over_time = pandas_df.groupby('searchDate')['totalFare'].mean()\n","\n","plt.figure(figsize=(12, 6))\n","plt.plot(average_fare_over_time.index, average_fare_over_time, marker='o')\n","plt.title('Average Total Fare Over Time')\n","plt.xlabel('Date')\n","plt.ylabel('Average Total Fare (USD)')\n","plt.grid()\n","plt.xticks(rotation=45)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"e6b06fe3","metadata":{},"outputs":[],"source":["# fare comparison of non-stop vs connecting flights\n","plt.figure(figsize=(10, 6))\n","sns.violinplot(x='isNonStop', y='totalFare', data=pandas_df)\n","plt.title('Total Fare: Non-Stop vs. Connecting Flights')\n","plt.xlabel('Non-Stop Flight')\n","plt.ylabel('Total Fare (USD)')\n","plt.xticks([0, 1], ['Connecting', 'Non-Stop'])\n","plt.grid()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"ff424748","metadata":{},"outputs":[],"source":["# analyze fare variations between diff routes\n","plt.figure(figsize=(12, 8))\n","sns.boxplot(x='startingAirport', y='totalFare', data=pandas_df)\n","plt.title('Total Fare by Starting Airport')\n","plt.xlabel('Starting Airport')\n","plt.ylabel('Total Fare (USD)')\n","plt.xticks(rotation=45)\n","plt.grid()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"id":"37bc159b","metadata":{},"outputs":[],"source":["# average total fare by airline\n","average_fare_by_airline = pandas_df.groupby('segmentsAirlineName')['totalFare'].mean().sort_values()\n","plt.figure(figsize=(10, 6))\n","average_fare_by_airline.plot(kind='barh')\n","plt.title('Average Total Fare by Airline')\n","plt.xlabel('Average Total Fare (USD)')\n","plt.ylabel('Airline')\n","plt.grid()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"id":"73aff794","metadata":{},"outputs":[],"source":["# use a histogram to analyze how ticket prices are distributed across all flights\n","plt.figure(figsize=(10, 6))\n","sns.histplot(pandas_df['totalFare'], bins=30, kde=True)\n","plt.title('Distribution of Total Fare for One-Way Flights')\n","plt.xlabel('Total Fare (USD)')\n","plt.ylabel('Frequency')\n","plt.grid()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"132cc7f2","metadata":{},"outputs":[],"source":["# see if there's a correlation between num of seats remaining and total fare\n","plt.figure(figsize=(10, 6))\n","sns.scatterplot(x='seatsRemaining', y='totalFare', data=pandas_df)\n","plt.title('Seats Remaining vs. Total Fare')\n","plt.xlabel('Seats Remaining')\n","plt.ylabel('Total Fare (USD)')\n","plt.grid()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"id":"5e9d8e7e","metadata":{},"outputs":[],"source":["!jupyter nbconvert --to pdf EDA.ipynb\n"]},{"cell_type":"code","execution_count":null,"id":"da90a82c","metadata":{},"outputs":[],"source":["# save the EDA to a Parquet file\n","EDA_data_path = \"gs://my-bigdatatech-project-jl/landing/EDA.ipynb\"\n","df.write.parquet(EDA_data_path)"]},{"cell_type":"code","execution_count":null,"id":"7f25ad9b","metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":5}